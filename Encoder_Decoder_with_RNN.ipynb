{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbvHpkC7vHd2uZBjckAyAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kim-Jeong-Ju/AI_Modeling_NLP/blob/main/Encoder_Decoder_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages and Modules Importation**"
      ],
      "metadata": {
        "id": "hJR1IHbBIZwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O_aUhXcuDV7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8239a188-a275-431f-8a05-a0138b0a7817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import urllib.request\n",
        "import urllib3\n",
        "import unicodedata\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install sentencepiece\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Masking, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoder-Decoder with RNN, RNN을 이용한 인코더-디코더**"
      ],
      "metadata": {
        "id": "yzqZF2BTIyT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Character-Level Neural Machine Translation(Seq2Seq), 문자 레벨 기계 변역기**  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 기본적으로 Seq2Seq 모델은 **Input sequence와 Output Sequence의 길이가 다름**\n",
        "- **성능이 좋은 기계 번역기를 구현**하기 위해서는 **방대한 양의 Dataset**이 필요\n",
        "- 기계 번역기 학습을 위해 Train Dataset으로 **Parallel Corpus(병렬 코퍼스)가 필요**  \n",
        "  *Parallel Corpus : 2개 이상의 언어가 병렬적으로 구성된 corpus*"
      ],
      "metadata": {
        "id": "0jxQL3Yge1x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "http = urllib3.PoolManager()                            # Reference = https://pparkst.tistory.com/32\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = \"fra-eng.zip\"\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "with http.request(\"GET\", url, preload_content=False) as r, open(zipfilename, \"wb\") as out_file:\n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "lines = pd.read_csv(\"fra.txt\", names=[\"src\", \"tar\", \"lic\"], sep=\"\\t\")\n",
        "del lines[\"lic\"]\n",
        "print(\"Total Length of samples =\", len(lines))\n",
        "print()\n",
        "\n",
        "lines = lines.loc[:, \"src\":\"tar\"]                               # Reference : https://bigdaheta.tistory.com/41\n",
        "lines = lines[:60000]\n",
        "lines.tar = lines.tar.apply(lambda x: \"\\t \" + x + \" \\n\")        # <sos>를 의미하는 \\t와 <eos>를 의미하는 \\n를 삽입\n",
        "\n",
        "src_vocab = set()                                               # 문자 집합 생성\n",
        "for line in lines.src:\n",
        "    for char in line:\n",
        "        src_vocab.add(char)\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)\n",
        "\n",
        "src_vocab_size = len(src_vocab) + 1\n",
        "tar_vocab_size = len(tar_vocab) + 1\n",
        "print(\"Source 문장의 char 집합 크기 =\", src_vocab_size)\n",
        "print(\"Target 문장의 char 집합 크기 =\", tar_vocab_size)\n",
        "print()\n",
        "\n",
        "src_vocab = sorted(list(src_vocab))                                             # 각 문자에 index 부여\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "\n",
        "encoder_input = []                                  # Encoder의 Input을 위한 Integer Encoding 수행\n",
        "for line in lines.src:\n",
        "    encoded = []\n",
        "    for char in line:\n",
        "        encoded.append(src_to_index[char])\n",
        "    encoder_input.append(encoded)\n",
        "\n",
        "decoder_input = []                                  # Decoder의 Input을 위한 Integer Encoding 수행\n",
        "for line in lines.tar:\n",
        "    encoded = []\n",
        "    for char in line:\n",
        "        encoded.append(tar_to_index[char])\n",
        "    decoder_input.append(encoded)\n",
        "\n",
        "decoder_target = []                                 # Decoder의 target값에는 <sos>에 해당하는 \\t(index = 1)가 필요 없음\n",
        "for line in lines.tar:\n",
        "    timestep = 0\n",
        "    encoded = []\n",
        "    for char in line:\n",
        "        if timestep > 0:\n",
        "            encoded.append(tar_to_index[char])\n",
        "        timestep += 1\n",
        "    decoder_target.append(encoded)\n",
        "\n",
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print(\"Source Sentence Maximum =\", max_src_len)\n",
        "print(\"Target Sentence Maximum =\", max_tar_len)\n",
        "\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding=\"post\")        # padding 작업 수행\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding=\"post\")\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding=\"post\")\n",
        "\n",
        "encoder_input = to_categorical(encoder_input)                                           # One-Hot Encoding 수행\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRAPBGfapyzj",
        "outputId": "beb2e445-37e9-44c8-8acd-27b128c8975f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Length of samples = 197463\n",
            "\n",
            "Source 문장의 char 집합 크기 = 79\n",
            "Target 문장의 char 집합 크기 = 105\n",
            "\n",
            "Source Sentence Maximum = 23\n",
            "Target Sentence Maximum = 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)                   # Encoder의 hidden cell을 Decoder로 넘겨주기 위해 return_state=True로 설정\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)    # state_h = hidden state, state_c = cell state\n",
        "encoder_states = [state_h, state_c]                                 # Decoder로 전달하게 될 Context Vector = [hidden state, cell state]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)\n",
        "print()\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "71BiXQKS7DIB",
        "outputId": "b3354aa4-4850-4db8-af0b-43fe7820f760"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 79)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 105)]  0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        344064      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  370688      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 105)    26985       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 741,737\n",
            "Trainable params: 741,737\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "\n",
            "Epoch 1/40\n",
            "750/750 [==============================] - 407s 537ms/step - loss: 0.7413 - val_loss: 0.6683\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 396s 528ms/step - loss: 0.4593 - val_loss: 0.5428\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 393s 524ms/step - loss: 0.3834 - val_loss: 0.4751\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 404s 538ms/step - loss: 0.3410 - val_loss: 0.4393\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 396s 528ms/step - loss: 0.3136 - val_loss: 0.4126\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 396s 528ms/step - loss: 0.2920 - val_loss: 0.3960\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 393s 524ms/step - loss: 0.2756 - val_loss: 0.3828\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 398s 530ms/step - loss: 0.2621 - val_loss: 0.3742\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 395s 527ms/step - loss: 0.2511 - val_loss: 0.3671\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 400s 533ms/step - loss: 0.2417 - val_loss: 0.3623\n",
            "Epoch 11/40\n",
            " 32/750 [>.............................] - ETA: 5:30 - loss: 0.2376"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0836bc7be22f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(encoder_model, show_shapes=True)\n",
        "print()\n",
        "\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
        "decoder_model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(decoder_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "UbalzBZP8sZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5674a162-b743-4c25-c5ee-2e5e40028fd9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 79)]        0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 256),             344064    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 344,064\n",
            "Trainable params: 344,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None, 105)]  0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  370688      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'input_3[0][0]',                \n",
            "                                 (None, 256)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 105)    26985       ['lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 397,673\n",
            "Trainable params: 397,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = dict((idx, char) for char, idx in src_to_index.items())\n",
        "index_to_tar = dict((idx, char) for char, idx in tar_to_index.items())\n",
        "\n",
        "def decode_seq(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)     # 입력으로부터 Encoder의 states를 얻음\n",
        "\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))       # <sos>에 해당하는 One-Hot Vector 생성\n",
        "    target_seq[0, 0, tar_to_index[\"\\t\"]] = 1.\n",
        "\n",
        "    stop_cond = False\n",
        "    decoded_sent = \"\"\n",
        "\n",
        "    while not stop_cond:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)                                    # 이전 시점의 states_value를 현 시점의 초기 상태로 사용\n",
        "        print(f\"output_tokens.shape = {output_tokens.shape}, hidden.shape = {h.shape}, cell.shape = {c.shape}\")\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])                # 예측 결과를 문자로 반환\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        decoded_sent += sampled_char                                            # 현 시점의 예측 문자를 예측 문장에 추가\n",
        "        print(f\"Decoded Sentence = {decoded_sent}\")\n",
        "\n",
        "        if sampled_char == \"\\n\" or len(decoded_sent) > max_tar_len:             # <eos>에 도달하거나 max_len을 초과하면 stop\n",
        "            stop_cond == True\n",
        "        \n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))                           # 현 시점의 예측 결과를 다음 시점의 input으로 사용하기 위한 저장\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]                                                   # 현 시점의 states_value를 다음 시점의 input으로 사용하기 위한 저장\n",
        "    \n",
        "    return decoded_sent\n",
        "\n",
        "for seq_index in [3, 50, 100, 300, 1001]:                       # Input Sentence의 index들\n",
        "    input_seq = encoder_input[seq_index:seq_index+1]\n",
        "    decoded_sentence = decode_seq(input_seq)\n",
        "\n",
        "    print(\"Input Sentence =\", lines.src[seq_index])\n",
        "    print(\"Target Sentence =\", lines.tar[seq_index][2:len(lines.tar[seq_index])-1])     # \\t와 \\n을 제외하고 출력\n",
        "    print(\"Predict Sentence =\", decoded_sentence[1:len(decoded_sentence)-1])            # \\n을 제외하고 출력\n",
        "\n",
        "    print(35 * \"-\")\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kf_YNRHLX2Ry",
        "outputId": "c3a9e6ba-3b69-472e-c471-d835ad26a36d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 482ms/step\n",
            "1/1 [==============================] - 0s 458ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  A\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Al\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  All\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Alle\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-v\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vo\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vou\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vous\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vous \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vous !\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vous ! \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n",
            "Decoded Sentence =  Allez-vous ! \n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "output_tokens.shape = (1, 1, 105), hidden.shape = (1, 256), cell.shape = (1, 256)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5bff92d6a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m                       \u001b[0;31m# Input Sentence의 index들\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Sentence =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d5bff92d6a2f>\u001b[0m in \u001b[0;36mdecode_seq\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# 예측 결과를 문자로 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msampled_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_to_tar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdecoded_sent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msampled_char\u001b[0m                                            \u001b[0;31m# 현 시점의 예측 문자를 예측 문장에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word-Level Neural Machine Translation(Seq2Seq), 단어 레벨 기계 변역기**"
      ],
      "metadata": {
        "id": "Pw4wH-80Tc2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "http = urllib3.PoolManager()                            # URL library 3 Reference = https://pparkst.tistory.com/32\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = \"fra-eng.zip\"\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "with http.request(\"GET\", url, preload_content=False) as r, open(zipfilename, \"wb\") as out_file:\n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "num_samples = 33000\n",
        "\n",
        "def unicode_to_ascii(string):                           # UnicodeData Reference = https://docs.python.org/ko/3/library/unicodedata.html\n",
        "    return \"\".join(char for char in unicodedata.normalize(\"NFD\", string) if unicodedata.category(char) != \"Mn\")     # 프랑스어 accent 삭제(ex. déjà diné -> deja dine)\n",
        "\n",
        "def preproc_sent(sent):\n",
        "    sent = unicode_to_ascii(sent.lower())                   # 문장 소문자화 및 정규화\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)              # 단어와 구두점 사이에 공백 삽입 \n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)             # re.sub() 내의 문자들 제외하고 나머지는 모두 공백으로 변환\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)                        # 다수의 공백을 1개의 공백으로 변환\n",
        "    return sent\n",
        "\n",
        "eng_sent = u\"Have you had dinner?\"\n",
        "fra_sent = u\"Avez-vous déjà diné?\"\n",
        "print(\"Before Preproc English Sentence =\", eng_sent)\n",
        "print(\"After Preproc English Sentence =\", preproc_sent(eng_sent))\n",
        "print(\"Before Preproc French Sentence =\", fra_sent)\n",
        "print(\"After Preproc French Sentence =\", preproc_sent(fra_sent))"
      ],
      "metadata": {
        "id": "QO1i2H9JpzT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e2ccfb-806b-4402-e480-86ce6bb30e3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Preproc English Sentence = Have you had dinner?\n",
            "After Preproc English Sentence = have you had dinner ?\n",
            "Before Preproc French Sentence = Avez-vous déjà diné?\n",
            "After Preproc French Sentence = avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preproc_data():                                                        # 모든 데이터들에 대한 전처리 + Teacher Forcing을 위한 3가지 list 생성\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "    with open(\"fra.txt\", \"r\") as lines:\n",
        "        for i, line in enumerate(lines):\n",
        "            src_line, tar_line, _ = line.strip().split(\"\\t\")\n",
        "\n",
        "            src_line = [word for word in preproc_sent(src_line).split()]\n",
        "            tar_line = preproc_sent(tar_line)\n",
        "            tar_line_in = [word for word in (\"<sos>\" + tar_line).split()]\n",
        "            tar_line_out = [word for word in (tar_line + \"<eos>\").split()]\n",
        "\n",
        "            encoder_input.append(src_line)\n",
        "            decoder_input.append(tar_line_in)\n",
        "            decoder_target.append(tar_line_out)\n",
        "\n",
        "            if i == num_samples - 1:\n",
        "                break\n",
        "    \n",
        "    return encoder_input, decoder_input, decoder_target\n",
        "\n",
        "eng_sents_in, fra_sents_in, fra_sents_out = load_preproc_data()\n",
        "\n",
        "eng_tokenizer = Tokenizer(filters=\"\", lower=False)                              # Integer Encoding & padding 작업 수행\n",
        "eng_tokenizer.fit_on_texts(eng_sents_in)\n",
        "encoder_input = eng_tokenizer.texts_to_sequences(eng_sents_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "fra_tokenizer = Tokenizer(filters=\"\", lower=False)\n",
        "fra_tokenizer.fit_on_texts(fra_sents_in)\n",
        "fra_tokenizer.fit_on_texts(fra_sents_out)\n",
        "decoder_input = fra_tokenizer.texts_to_sequences(fra_sents_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_target = fra_tokenizer.texts_to_sequences(fra_sents_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")\n",
        "\n",
        "print('Input of Encoder Shape =', encoder_input.shape)\n",
        "print('Input of Decoder Shape =', decoder_input.shape)\n",
        "print('Target of Decoder Shape =', decoder_target.shape)"
      ],
      "metadata": {
        "id": "1DbSr34BdI6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34a44aa-9f7f-4fac-e84e-2b50ddb55e7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input of Encoder Shape = (33000, 8)\n",
            "Input of Decoder Shape = (33000, 15)\n",
            "Target of Decoder Shape = (33000, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = encoder_input.shape[1]\n",
        "max_tar_len = decoder_input.shape[1]\n",
        "print('source 문장의 최대 길이 =', max_src_len)\n",
        "print('target 문장의 최대 길이 =', max_tar_len)\n",
        "print()\n",
        "\n",
        "src_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "tar_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 = {:d}\".format(src_vocab_size))\n",
        "print(\"프랑스어 단어 집합의 크기 = {:d}\".format(tar_vocab_size))\n",
        "\n",
        "src_to_index = eng_tokenizer.word_index\n",
        "index_to_src = eng_tokenizer.index_word\n",
        "tar_to_index = fra_tokenizer.word_index\n",
        "index_to_tar = fra_tokenizer.index_word\n",
        "\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "encoder_input\n",
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n",
        "\n",
        "valid_size = int(33000 * 0.1)\n",
        "encoder_input_train = encoder_input[:-valid_size]\n",
        "decoder_input_train = decoder_input[:-valid_size]\n",
        "decoder_target_train = decoder_target[:-valid_size]\n",
        "encoder_input_test = encoder_input[-valid_size:]\n",
        "decoder_input_test = decoder_input[-valid_size:]\n",
        "decoder_target_test = decoder_target[-valid_size:]"
      ],
      "metadata": {
        "id": "GLR929oMfVRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8427fbc-2e26-478e-aabe-92668055f81c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 = 8\n",
            "target 문장의 최대 길이 = 15\n",
            "\n",
            "영어 단어 집합의 크기 = 4672\n",
            "프랑스어 단어 집합의 크기 = 9307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_mask = Masking(mask_value=0.0)(encoder_emb)\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_mask)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb_layer = Embedding(tar_vocab_size, hidden_units)\n",
        "decoder_emb_1 = decoder_emb_layer(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0.0)(decoder_emb_1)\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=encoder_states)\n",
        "decoder_dense = Dense(tar_vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)\n",
        "print()\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), epochs=50, batch_size=128)"
      ],
      "metadata": {
        "id": "-CjHICeAleF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "140eb068-4758-4930-a06e-82a0f66f3103"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 64)     299008      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     595648      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 64)     0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, None, 64)     0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 64),         33024       ['masking[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 64),   33024       ['masking_1[0][0]',              \n",
            "                                 (None, 64),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 64)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 9307)   604955      ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,565,659\n",
            "Trainable params: 1,565,659\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "233/233 [==============================] - 150s 604ms/step - loss: 3.4328 - acc: 0.6535 - val_loss: 2.0611 - val_acc: 0.6580\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 132s 569ms/step - loss: 1.8812 - acc: 0.6721 - val_loss: 1.7386 - val_acc: 0.7209\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 133s 571ms/step - loss: 1.6122 - acc: 0.7270 - val_loss: 1.5160 - val_acc: 0.7331\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 136s 585ms/step - loss: 1.4035 - acc: 0.7580 - val_loss: 1.3264 - val_acc: 0.7798\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 133s 570ms/step - loss: 1.2250 - acc: 0.8039 - val_loss: 1.1622 - val_acc: 0.8205\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 130s 560ms/step - loss: 1.0651 - acc: 0.8421 - val_loss: 1.0169 - val_acc: 0.8611\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 135s 579ms/step - loss: 0.9297 - acc: 0.8694 - val_loss: 0.8982 - val_acc: 0.8780\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 131s 561ms/step - loss: 0.8230 - acc: 0.8872 - val_loss: 0.8075 - val_acc: 0.8950\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 131s 561ms/step - loss: 0.7394 - acc: 0.9003 - val_loss: 0.7356 - val_acc: 0.9043\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 135s 582ms/step - loss: 0.6708 - acc: 0.9103 - val_loss: 0.6762 - val_acc: 0.9140\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 125s 538ms/step - loss: 0.6125 - acc: 0.9185 - val_loss: 0.6260 - val_acc: 0.9216\n",
            "Epoch 12/50\n",
            "175/233 [=====================>........] - ETA: 31s - loss: 0.5664 - acc: 0.9249"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-eced9437c8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_target_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(encoder_model, show_shapes=True)\n",
        "print()\n",
        "\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_emb_2 = decoder_emb_layer(decoder_inputs)\n",
        "decoder_outputs_2, state_h2, state_c2 = decoder_lstm(decoder_emb_2, initial_state=decoder_states_inputs)\n",
        "decoder_states_2 = [state_h2, state_c2]\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs_2] + decoder_states_2)\n",
        "decoder_model.summary()\n",
        "print()\n",
        "tf.keras.utils.plot_model(decoder_model, show_shapes=True)\n",
        "print()\n",
        "\n",
        "def decode_seq(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tar_to_index[\"<sos>\"]\n",
        "\n",
        "    stop_cond = False\n",
        "    decoded_sent = \"\"\n",
        "\n",
        "    while not stop_cond:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        decoded_sent += sampled_char\n",
        "\n",
        "        if sampled_char == \"<eos>\" or len(decoded_sent) > 50:\n",
        "            stop_cond = True\n",
        "        \n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sent"
      ],
      "metadata": {
        "id": "my8kh6MqnYEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cabc46-d82b-493f-da20-51a55fd742a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 64)          299008    \n",
            "                                                                 \n",
            " masking (Masking)           (None, None, 64)          0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, 64),              33024     \n",
            "                              (None, 64),                        \n",
            "                              (None, 64)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 332,032\n",
            "Trainable params: 332,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     595648      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[1][0]',            \n",
            "                                 (None, 64),                      'input_7[0][0]',                \n",
            "                                 (None, 64)]                      'input_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 628,672\n",
            "Trainable params: 628,672\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_src(input_seq):          # 영어 Input Sentence의 Integer Sequence 형태를 문장으로 변환\n",
        "    sent = \"\"\n",
        "    for encoded_word in input_seq:\n",
        "        if encoded_word != 0:\n",
        "            sent += index_to_src[encoded_word] + \" \"\n",
        "    return sent\n",
        "\n",
        "def seq_to_tar(input_seq):          # 프랑스어 Predict Sentence의 Integer Sequence 형태를 문장으로 변환\n",
        "    sent = \"\"\n",
        "    for encoded_word in input_seq:\n",
        "        if encoded_word != 0 and encoded_word != tar_to_index[\"<sos>\"] and encoded_word != tar_to_index[\"<eos>\"]:\n",
        "            sent += index_to_tar[encoded_word] + \" \"\n",
        "    return sent\n",
        "\n",
        "for seq_index in [3,50,100,300,1001]:                                           # Train Data에 대해 Check\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_seq(input_seq)\n",
        "  \n",
        "  print(\"Input English Sentence :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"Target French Sentence :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"Predict French Sentence :\",decoded_sentence[1:-5])                     # 맨 앞에 space, 맨 뒤에 '<eos>'를 제외하고 출력\n",
        "  print(\"-\"*50)\n",
        "print()\n",
        "for seq_index in [3,50,100,300,1001]:                                           # Test Data에 대해 Check\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_seq(input_seq)\n",
        "  \n",
        "  print(\"Input English Sentence :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"Target French Sentence :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"Predict French Sentence :\",decoded_sentence[1:-5])                     # 맨 앞에 space, 맨 뒤에 '<eos>'를 제외하고 출력\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "MEnW46nEp3cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c16f50-2630-4870-e77a-d346b0585b52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 442ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input English Sentence : tom loved boston . \n",
            "Target French Sentence : <sos>tom a adore boston . \n",
            "Predict French Sentence : mede!<eos>came.<eos>le.<eos>caen.<eos>le.<eos\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input English Sentence : tom is happy . \n",
            "Target French Sentence : <sos>tom est content . \n",
            "Predict French Sentence : mede!<eos>came.<eos>le.<eos>caen.<eos>le.<eos\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Input English Sentence : they all scoffed . \n",
            "Target French Sentence : <sos>elles ont toutes raille . \n",
            "Predict French Sentence : meellea.<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input English Sentence : i disobeyed you . \n",
            "Target French Sentence : <sos>je vous ai desobei . \n",
            "Predict French Sentence : elleasuis.<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Input English Sentence : something bit me . \n",
            "Target French Sentence : <sos>quelque chose m a mordu . \n",
            "Predict French Sentence : ameellenmonlellea.<eos>caen.<eos>caen.<eos>le.\n",
            "--------------------------------------------------\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input English Sentence : you d love it . \n",
            "Target French Sentence : <sos>tu adorerais ca . \n",
            "Predict French Sentence : elleal?<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input English Sentence : i rang the bell . \n",
            "Target French Sentence : <sos>j ai fait sonner la cloche . \n",
            "Predict French Sentence : elleasuis.<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Input English Sentence : it s close by . \n",
            "Target French Sentence : <sos>c est a proximite . \n",
            "Predict French Sentence : mede!<eos>came.<eos>le.<eos>caen.<eos>le.<eos\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Input English Sentence : they were yours . \n",
            "Target French Sentence : <sos>ils etaient les votres . \n",
            "Predict French Sentence : meelleasuis.<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input English Sentence : how about running ? \n",
            "Target French Sentence : <sos>et si vous couriez ? \n",
            "Predict French Sentence : elleal?<eos>caen.<eos>caen.<eos>le.<eos>caen.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}