{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6I8eO5yduYko75fHdWmbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kim-Jeong-Ju/AI_Modeling_NLP/blob/main/Tagging_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages and Modules Importation**"
      ],
      "metadata": {
        "id": "hJR1IHbBIZwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_aUhXcuDV7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38d34d4-5443-46f1-f80e-8371f73daaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Embedding, Dense, LSTM, Bidirectional, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tagging Task, 태깅 작업**"
      ],
      "metadata": {
        "id": "yzqZF2BTIyT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **POS(Part-Of-Speech) Tagging with Bi-LSTM, 양방향 LSTM을 통한 품사 태깅**  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- **다대다 문제**이므로 **LSTM의 `return_sequences=True`**로 설정, **양방향 사용**을 위해 **`Bidirectional()` 사용**\n",
        "- target label에 대해 One-Hot Encoding 이후 Loss function으로 `categorical_crossentropy` 사용이 아닌, **원본 target label을 사용하되 Loss function으로 `sparse_categorical_crossentropy` 사용**\n",
        "- data의 padding으로 인해 0의 값이 많아질 때에는 **`Embedding()`의 argument로 `mask_zero=True`를 설정하면 0의 값은 연산에서 제외**\n",
        "- 출력층에 **`TimeDistributed()`를 사용해 LSTM의 모든 time step에서 출력층을 사용**"
      ],
      "metadata": {
        "id": "0jxQL3Yge1x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sents = nltk.corpus.treebank.tagged_sents()      # 토큰화에 품사 태깅이 된 데이터 불러오기\n",
        "print(\"품사 태깅된 문장 갯수 =\", len(tagged_sents))\n",
        "print(tagged_sents[0])\n",
        "print()\n",
        "\n",
        "sents, pos_tags = [], []\n",
        "for tagged_sent in tagged_sents:\n",
        "    sent, tag_info = zip(*tagged_sent)      # 각 샘플에서 단어는 sent에, 품사 정보는 tag_info에 저장\n",
        "    sents.append(list(sent))\n",
        "    pos_tags.append(list(tag_info))\n",
        "\n",
        "print('Maximum Length = %d' % max(len(line) for line in sents))         # max_len으로의 padding을 위한 데이터의 길이 분포 확인 \n",
        "print('Average Length = %f' % (sum(map(len, sents)) / len(sents)))\n",
        "plt.hist([len(sent) for sent in sents], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "def tokenize(samples):                                  # Integer Encoding 수행\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(samples)\n",
        "    return tokenizer\n",
        "\n",
        "src_tokenizer = tokenize(sents)\n",
        "tar_tokenizer = tokenize(pos_tags)\n",
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size =\", vocab_size)\n",
        "print(\"Tagging Set Size =\", tag_size)\n",
        "print()\n",
        "\n",
        "X_train = src_tokenizer.texts_to_sequences(sents)\n",
        "y_train = tar_tokenizer.texts_to_sequences(pos_tags)\n",
        "\n",
        "max_len = 150          # padding 작업\n",
        "X_train = pad_sequences(X_train, padding=\"post\", maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding=\"post\", maxlen=max_len)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=777)\n",
        "print('Train Data Size = {}'.format(X_train.shape))\n",
        "print('Train Label Size = {}'.format(y_train.shape))\n",
        "print('Test Data Size = {}'.format(X_test.shape))\n",
        "print('Test Label Size = {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "SEHwmjDNj0xU",
        "outputId": "543de22c-b187-49cd-fa73-4260496b2f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "품사 태깅된 문장 갯수 = 3914\n",
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
            "\n",
            "Maximum Length = 271\n",
            "Average Length = 25.722024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary Size = 11388\n",
            "Tagging Set Size = 47\n",
            "\n",
            "Train Data Size = (3131, 150)\n",
            "Train Label Size = (3131, 150)\n",
            "Test Data Size = (783, 150)\n",
            "Test Label Size = (783, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=\"softmax\")))\n",
        "\n",
        "model.compile(optimizer=Adam(0.01), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "model.fit(X_train, y_train, epochs=7, batch_size=128, validation_data=(X_test, y_test))\n",
        "print()\n",
        "\n",
        "print(\"Test Accuracy = %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
        "print()\n",
        "\n",
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_tag = tar_tokenizer.index_word\n",
        "\n",
        "idx = 10                                                                        # 예측하고 싶은 데이터의 index 설정\n",
        "y_pred = model.predict(np.array([X_test[idx]]))                                 # 예측한 y_pred return\n",
        "print(f\"Shape of y_pred = {y_pred.shape}\")\n",
        "print()\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=-1)                                             # One-Hot Encoding을 Integer Encoding으로 변환, armax의 axis=-1이면 뒤에서부터 순서대로 최댓값의 index 반환\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "for word, tag, pred in zip(X_test[idx], y_test[idx], y_pred[0]):\n",
        "    if word != 0:       # 0번 PAD(padding) token은 제외\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_tag[tag].upper(), index_to_tag[pred].upper()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldsb4zZsnnNP",
        "outputId": "96bc0763-e342-4aeb-b447-0dbd149598f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "25/25 [==============================] - 55s 2s/step - loss: 0.4161 - acc: 0.3853 - val_loss: 0.1466 - val_acc: 0.8077\n",
            "Epoch 2/7\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.0599 - acc: 0.9143 - val_loss: 0.0420 - val_acc: 0.9294\n",
            "Epoch 3/7\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.0150 - acc: 0.9739 - val_loss: 0.0388 - val_acc: 0.9336\n",
            "Epoch 4/7\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.0086 - acc: 0.9844 - val_loss: 0.0396 - val_acc: 0.9365\n",
            "Epoch 5/7\n",
            "25/25 [==============================] - 39s 2s/step - loss: 0.0056 - acc: 0.9906 - val_loss: 0.0409 - val_acc: 0.9360\n",
            "Epoch 6/7\n",
            "25/25 [==============================] - 39s 2s/step - loss: 0.0040 - acc: 0.9940 - val_loss: 0.0430 - val_acc: 0.9350\n",
            "Epoch 7/7\n",
            "25/25 [==============================] - 40s 2s/step - loss: 0.0027 - acc: 0.9964 - val_loss: 0.0430 - val_acc: 0.9353\n",
            "\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0430 - acc: 0.9353\n",
            "Test Accuracy = 0.9353\n",
            "\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "Shape of y_pred = (1, 150, 47)\n",
            "\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "in               : IN      IN\n",
            "addition         : NN      NN\n",
            ",                : ,       ,\n",
            "buick            : NNP     NNP\n",
            "is               : VBZ     VBZ\n",
            "a                : DT      DT\n",
            "relatively       : RB      RB\n",
            "respected        : VBN     VBN\n",
            "nameplate        : NN      NN\n",
            "among            : IN      IN\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "card             : NN      NN\n",
            "holders          : NNS     NNS\n",
            ",                : ,       ,\n",
            "says             : VBZ     VBZ\n",
            "0                : -NONE-  -NONE-\n",
            "*t*-1            : -NONE-  -NONE-\n",
            "an               : DT      DT\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "spokeswoman      : NN      NN\n",
            ".                : .       .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BIO(Begin-Inside-Outside) Expression of NER(Named Unity Recognition), 개체명 인식의 BIO 표현**  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **CONLL2003 : NER 위한 전통적인 영어 데이터셋**\n",
        "*Link in Bio : https://paperswithcode.com/dataset/conll-2003*  \n",
        "*Link in Bio : https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html*\n",
        "\n",
        "```\n",
        "EU NNP B-NP B-ORG\n",
        "rejects VBZ B-VP O\n",
        "German JJ B-NP B-MISC\n",
        "call NN I-NP O\n",
        "to TO B-VP O\n",
        "boycott VB I-VP O\n",
        "British JJ B-NP B-MISC\n",
        "lamb NN I-NP O\n",
        ". . O O\n",
        "\n",
        "Peter NNP B-NP B-PER\n",
        "Blackburn NNP I-NP I-PER\n",
        "```\n",
        "\n",
        "- **Data 형식 : [Word] [POS] [Chunk Tagging] [NER]**  \n",
        "ex) 예를 들어서 EU 옆에 붙어있는 **NNP는 고유 명사 단수형**, rejects 옆에 있는 **VBZ는 3인칭 단수 동사 현재형**  \n",
        "- **Tagging의 종류 : LOC는 location, ORG는 organization, PER은 person, MISC는 miscellaneous**  \n",
        "- 개체명의 시작 부분이면서 Organization을 의미하는 **German에는 B-ORG라는 개체명 tagging**을 붙임. But German 그 자체로 개체명 하나이기 때문에 거기서 개체명 인식은 종료되면서 뒤에 I가 별도로 붙는 단어가 나오지 않음. German 뒤에 나오는 **call은 개체명이 아니기 때문에 O이 tagging**\n",
        "- 9번째 line에서 문장이 끝나고 한줄 공백을 삽입한 후, 11번째 line에 다음 문장이 시작됨\n",
        "- Peter는 개체명이 시작되면서 person에 해당되기 때문에 B-PER이라는 개체명 tagging이 붙음. 그리고 아직 개체명에 대한 인식은 끝나지 않았기 때문에 뒤에 붙는 Blackburn에서는 I가 나오면서 **I-PER이 개체명 tagging**으로 붙게 됨. 즉, **Peter Blackburn이 person에 속하는 하나의 개체명**"
      ],
      "metadata": {
        "id": "Pw4wH-80Tc2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"Colab Notebooks\", \"CAU AI Class\", \"data\", \"train.txt\"), \"r\")\n",
        "\n",
        "tagged_sents = []               # 단어와 개체명 tag의 pair로 이루어진 sent들의 list\n",
        "sent = []                       # 공백으로 문장 간 구분\n",
        "\n",
        "for line in file:\n",
        "    if len(line) == 0 or line.startswith(\"-DOCSTART\") or line[0] == \"\\n\":\n",
        "        if len(sent) > 0:\n",
        "            tagged_sents.append(sent)           # 공백 line이 하나의 sent가 끝난 이후에 나왔다면, 지금까지 만들어진 sent를 tagged_sent에 추가\n",
        "            sent = []                           # sent 리스트는 초기화\n",
        "        continue\n",
        "    \n",
        "    splits = line.split(\" \")                        # 공백 기준 split\n",
        "    splits[-1] = re.sub(r\"\\n\", \"\", splits[-1])      # 줄바꿈 문자 제거\n",
        "    word = splits[0].lower()                        # 소문자화\n",
        "    sent.append([word, splits[-1]])                 # 단어와 개체명 tag만 기록\n",
        "\n",
        "print(\"Total Sample Size =\", len(tagged_sents))\n",
        "print()\n",
        "\n",
        "sents, ner_tags = [], []\n",
        "for tagged_sent in tagged_sents:\n",
        "    sent, tag_info = zip(*tagged_sent)\n",
        "    sents.append(list(sent))\n",
        "    ner_tags.append(list(tag_info))\n",
        "\n",
        "print('Maximum Length : %d' % max(len(l) for l in sents))               # 문장 sample의 길이 분포 확인\n",
        "print('Average Length : %f' % (sum(map(len, sents)) / len(sents)))\n",
        "plt.hist([len(s) for s in sents], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ycaFKk8rjzLV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "6efb7282-839e-4fb9-de8e-3f993a45ba23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sample Size = 14041\n",
            "\n",
            "Maximum Length : 113\n",
            "Average Length : 14.501887\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 4000\n",
        "\n",
        "src_tokenizer = Tokenizer(num_words=max_words, oov_token=\"OOV\")         # for 문장 data\n",
        "src_tokenizer.fit_on_texts(sents)\n",
        "tar_tokenizer = Tokenizer()                                             # for Tagging data\n",
        "tar_tokenizer.fit_on_texts(ner_tags)\n",
        "\n",
        "vocab_size = max_words\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('Vocabulary Size = {}'.format(vocab_size))\n",
        "print('Tagging Set Size = {}'.format(tag_size))\n",
        "print()\n",
        "\n",
        "X_train = src_tokenizer.texts_to_sequences(sents)\n",
        "y_train = tar_tokenizer.texts_to_sequences(ner_tags)\n",
        "\n",
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "\n",
        "decoded = []\n",
        "for idx in X_train[0]:                                                          # OOV로 대체된 것들에 대해 sample data 디코딩하여 확인\n",
        "    decoded.append(index_to_word[idx])\n",
        "print('Original Sentence = {}'.format(sents[0]))\n",
        "print('OOV Sentence = {}'.format(decoded))\n",
        "print()\n",
        "\n",
        "max_len = 70                                                                    # padding 작업 수행\n",
        "X_train = pad_sequences(X_train, padding=\"post\", maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding=\"post\", maxlen=max_len)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=777)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)\n",
        "print('Train Data Size : {}'.format(X_train.shape))\n",
        "print('Train Label Size : {}'.format(y_train.shape))\n",
        "print('Test Data Size : {}'.format(X_test.shape))\n",
        "print('Test Label Size : {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ItFM22GdUFx",
        "outputId": "116e3ed1-a7e1-413d-9acb-11fc99e6220b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size = 4000\n",
            "Tagging Set Size = 10\n",
            "\n",
            "Original Sentence = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "OOV Sentence = ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n",
            "\n",
            "Train Data Size : (11232, 70)\n",
            "Train Label Size : (11232, 70, 10)\n",
            "Test Data Size : (2809, 70)\n",
            "Test Label Size : (2809, 70, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=\"softmax\")))\n",
        "model.summary()\n",
        "print()\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "model.fit(X_train, y_train, epochs=8, batch_size=128, validation_data=(X_test, y_test))\n",
        "print(\"Test Accuracy = %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
        "print()\n",
        "\n",
        "idx = 10                                                                        # 확인하고 싶은 테스트용 sample index\n",
        "y_pred = model.predict(np.array([X_test[idx]]))                                 # 입력한 테스트용 샘플에 대해서 y_pred return\n",
        "y_pred = np.argmax(y_pred, axis=-1)                                             # 확률값 벡터를 Integer Encoding으로 변경\n",
        "true = np.argmax(y_test[idx], -1)                                               # One-Hot Vector를 Integer Encoding으로 변경\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for word, tag, pred in zip(X_test[idx], true, y_pred[0]):\n",
        "    if word != 0:           # PAD(padding) token값은 제외\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag].upper(), index_to_ner[pred].upper()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlcWEwGFhez4",
        "outputId": "9233317b-88de-4514-9943-fc2bfea842fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 70, 128)           512000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 70, 256)          263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 70, 10)           2570      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 777,738\n",
            "Trainable params: 777,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 68s 681ms/step - loss: 0.1994 - acc: 0.8237 - val_loss: 0.1313 - val_acc: 0.8333\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 54s 618ms/step - loss: 0.1061 - acc: 0.8470 - val_loss: 0.0838 - val_acc: 0.8757\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 54s 617ms/step - loss: 0.0728 - acc: 0.8958 - val_loss: 0.0583 - val_acc: 0.9170\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 57s 651ms/step - loss: 0.0495 - acc: 0.9308 - val_loss: 0.0423 - val_acc: 0.9404\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 54s 618ms/step - loss: 0.0361 - acc: 0.9492 - val_loss: 0.0370 - val_acc: 0.9480\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 53s 604ms/step - loss: 0.0297 - acc: 0.9580 - val_loss: 0.0341 - val_acc: 0.9538\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 53s 603ms/step - loss: 0.0251 - acc: 0.9648 - val_loss: 0.0330 - val_acc: 0.9553\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 55s 621ms/step - loss: 0.0221 - acc: 0.9686 - val_loss: 0.0321 - val_acc: 0.9571\n",
            "88/88 [==============================] - 8s 86ms/step - loss: 0.0321 - acc: 0.9571\n",
            "Test Accuracy = 0.9571\n",
            "\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "sarah            : B-PER   B-PER\n",
            "brady            : I-PER   I-PER\n",
            ",                : O       O\n",
            "whose            : O       O\n",
            "republican       : B-MISC  B-MISC\n",
            "husband          : O       O\n",
            "was              : O       O\n",
            "OOV              : O       O\n",
            "OOV              : O       O\n",
            "in               : O       O\n",
            "an               : O       O\n",
            "OOV              : O       O\n",
            "attempt          : O       O\n",
            "on               : O       O\n",
            "president        : O       O\n",
            "ronald           : B-PER   B-PER\n",
            "reagan           : I-PER   I-PER\n",
            ",                : O       O\n",
            "took             : O       O\n",
            "centre           : O       O\n",
            "stage            : O       O\n",
            "at               : O       O\n",
            "the              : O       O\n",
            "democratic       : B-MISC  B-MISC\n",
            "national         : I-MISC  I-MISC\n",
            "convention       : I-MISC  I-MISC\n",
            "on               : O       O\n",
            "monday           : O       O\n",
            "night            : O       O\n",
            "to               : O       O\n",
            "OOV              : O       O\n",
            "president        : O       O\n",
            "bill             : B-PER   B-PER\n",
            "clinton          : I-PER   I-PER\n",
            "'s               : O       O\n",
            "gun              : O       O\n",
            "control          : O       O\n",
            "efforts          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    }
  ]
}